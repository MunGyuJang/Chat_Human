{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca9a3aa",
   "metadata": {
    "id": "6c594588"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import copy\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e2a7c8",
   "metadata": {
    "id": "97e70cae"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    bos_token = '<s>'\n",
    "    eos_token = '</s>'\n",
    "    usr_token = '<usr>'\n",
    "    pad_token = '<pad>'\n",
    "    sys_token = '<sys>'\n",
    "    unk_token = '<unk>'\n",
    "    mask_token = '<mask>'\n",
    "    max_len = 512\n",
    "    max_turns = 16\n",
    "    epochs = 1\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    learning_rate = 1e-4\n",
    "    model_name = \"skt/kogpt2-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f834cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;usr&gt; 나 운전면허 따야 하는데&lt;sys&gt; 너 따긴 했잖아?연수를 받아야지 너는&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;usr&gt; 내일은 산에 못가시나요?&lt;sys&gt; 산에 못가고 장보러 가야지.휴양림가서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;usr&gt; 오늘 도서관가서 책 빌려왔음&lt;sys&gt; 오호 도서관도 가나? 어디도서관?&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;usr&gt; 파운데이션 하나 같이 테스트 하러 가자&lt;sys&gt; 오 파운데이션 다 썼어?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;usr&gt; 비긴 어게인 다시 보고 싶다&lt;sys&gt; 아 나는 그거 또보고싶다고!&lt;usr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62657</th>\n",
       "      <td>&lt;usr&gt; 나 방금 병원 다녀왔어 ㅠㅠ&lt;sys&gt; 병원? 어디 아파ㅠ?&lt;usr&gt; 목이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62658</th>\n",
       "      <td>&lt;usr&gt; 영화볼 때 주인공 위주로 보는 편이야?&lt;sys&gt; 응 난 아무래도 주인공이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62659</th>\n",
       "      <td>&lt;usr&gt; 포도가 요즘 맛있더라고요.&lt;sys&gt; 무슨 포도 드셨어요?&lt;usr&gt; 샤인머...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62660</th>\n",
       "      <td>&lt;usr&gt; 오늘 문화센터 특강한던데 한번 가볼래?&lt;sys&gt; 그거 등록해야하는거 아니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62661</th>\n",
       "      <td>&lt;usr&gt; 회사에서 점심때 소외되는 느낌이에요.&lt;sys&gt; 왜요? 왕따에요?&lt;usr&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62662 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            conversation\n",
       "0      <usr> 나 운전면허 따야 하는데<sys> 너 따긴 했잖아?연수를 받아야지 너는<...\n",
       "1      <usr> 내일은 산에 못가시나요?<sys> 산에 못가고 장보러 가야지.휴양림가서 ...\n",
       "2      <usr> 오늘 도서관가서 책 빌려왔음<sys> 오호 도서관도 가나? 어디도서관?<...\n",
       "3      <usr> 파운데이션 하나 같이 테스트 하러 가자<sys> 오 파운데이션 다 썼어?...\n",
       "4      <usr> 비긴 어게인 다시 보고 싶다<sys> 아 나는 그거 또보고싶다고!<usr...\n",
       "...                                                  ...\n",
       "62657  <usr> 나 방금 병원 다녀왔어 ㅠㅠ<sys> 병원? 어디 아파ㅠ?<usr> 목이...\n",
       "62658  <usr> 영화볼 때 주인공 위주로 보는 편이야?<sys> 응 난 아무래도 주인공이...\n",
       "62659  <usr> 포도가 요즘 맛있더라고요.<sys> 무슨 포도 드셨어요?<usr> 샤인머...\n",
       "62660  <usr> 오늘 문화센터 특강한던데 한번 가볼래?<sys> 그거 등록해야하는거 아니...\n",
       "62661  <usr> 회사에서 점심때 소외되는 느낌이에요.<sys> 왜요? 왕따에요?<usr>...\n",
       "\n",
       "[62662 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv('./data/kakao_version.csv')\n",
    "data = pd.read_csv('./data/kakao_len384.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422122dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 100\n",
    "\n",
    "# data = pd.read_csv('./data/kakao_version_2.csv')\n",
    "data = data[:S].reset_index(drop=True)\n",
    "# data_train_val['conversation'] = data_train_val['conversation'].apply(lambda x: x.replace(\"키키\", \"ㅋㅋ\"))\n",
    "data['conversation'] = data['conversation'].apply(lambda x: x.replace(\"하하\", \"ㅎㅎ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4dd6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;usr&gt; 나 운전면허 따야 하는데&lt;sys&gt; 너 따긴 했잖아?연수를 받아야지 너는&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;usr&gt; 내일은 산에 못가시나요?&lt;sys&gt; 산에 못가고 장보러 가야지.휴양림가서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;usr&gt; 오늘 도서관가서 책 빌려왔음&lt;sys&gt; 오호 도서관도 가나? 어디도서관?&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;usr&gt; 파운데이션 하나 같이 테스트 하러 가자&lt;sys&gt; 오 파운데이션 다 썼어?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;usr&gt; 비긴 어게인 다시 보고 싶다&lt;sys&gt; 아 나는 그거 또보고싶다고!&lt;usr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>&lt;usr&gt; 나 오늘 차 계약했어.&lt;sys&gt; 어머. 내가 소개시켜준 딜러한테?&lt;usr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>&lt;usr&gt; 가족 여행을 어디로 갈까나&lt;sys&gt; 오 아직도 못 정했어?&lt;usr&gt; 웅웅...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>&lt;usr&gt; 나 보톡스 맞아볼려고!&lt;sys&gt; 그거 일회성이 아닌건 알고 있지? ㅋㅋ&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>&lt;usr&gt; 엄마 네일 한 지 좀 오래되지 않았어?&lt;sys&gt; 엄마는 원래 자주 안 해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>&lt;usr&gt; 오토바이 소리가 왜 다르지?&lt;sys&gt; 나도 그게 궁금했어&lt;usr&gt; 어떤 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         conversation\n",
       "0   <usr> 나 운전면허 따야 하는데<sys> 너 따긴 했잖아?연수를 받아야지 너는<...\n",
       "1   <usr> 내일은 산에 못가시나요?<sys> 산에 못가고 장보러 가야지.휴양림가서 ...\n",
       "2   <usr> 오늘 도서관가서 책 빌려왔음<sys> 오호 도서관도 가나? 어디도서관?<...\n",
       "3   <usr> 파운데이션 하나 같이 테스트 하러 가자<sys> 오 파운데이션 다 썼어?...\n",
       "4   <usr> 비긴 어게인 다시 보고 싶다<sys> 아 나는 그거 또보고싶다고!<usr...\n",
       "..                                                ...\n",
       "85  <usr> 나 오늘 차 계약했어.<sys> 어머. 내가 소개시켜준 딜러한테?<usr...\n",
       "86  <usr> 가족 여행을 어디로 갈까나<sys> 오 아직도 못 정했어?<usr> 웅웅...\n",
       "87  <usr> 나 보톡스 맞아볼려고!<sys> 그거 일회성이 아닌건 알고 있지? ㅋㅋ<...\n",
       "88  <usr> 엄마 네일 한 지 좀 오래되지 않았어?<sys> 엄마는 원래 자주 안 해...\n",
       "89  <usr> 오토바이 소리가 왜 다르지?<sys> 나도 그게 궁금했어<usr> 어떤 ...\n",
       "\n",
       "[90 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data[:-10]\n",
    "data_val = data[-10:]\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc66317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_split(dialogues):\n",
    "    dials = re.split('<usr> |<sys> ', dialogues)\n",
    "    dials = [dial.strip() for dial in dials if dial.strip()]\n",
    "    \n",
    "    return dials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c178a235",
   "metadata": {
    "id": "a4df84c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<usr> 내일은 산에 못가시나요?<sys> 산에 못가고 장보러 가야지.휴양림가서 산책해야지만보 걸을수 있을런지 모르겠다.<usr> 그러게요 이번주는 걷기 어플 주간미션달성 아직인가요?<sys> 이번주 주간미션 달성했어.획득한 리워드가 기다리고 있어요.<usr> 이번주도 하셨네요걷기운동으로 커피쿠폰 또 받을 수 있겠어요<sys> 그래. 별것아닌것 같아도 보람이 있다.<usr> 네 만보걷기는 어플 채우는 재미도 큰 거 같아요<sys> 건강을 위해서 걷기하는데 만보 채우는 재미도 있어.<usr> 네 걷기운동 안하면 어플이 빈털털이 느낌이라 아쉬운감이 있어요<sys> 어플도 채우고 건강도 챙기고 네가 이런저런 어플 알려줘서 재미도 있고 보람도 있어.<usr> 엄마가 걸어서 모으신 포인트를 유 용하게 사용하셔야 더 재밌을텐데요빵도 사드시고 많이 모으면 치킨도 사드시고 하세요 ㅎㅎ<sys> 그냥 걸어도 건강해져서 좋은데 덤으로 생기는 포인트들이 있으니 더 좋아한달동안 걸어서 토스적립금도 재밌고오늘도 계좌로 입금했어.<usr> 매달 말일에 하면 잊지않고 좋겠네요\n",
      "\n",
      "['내일은 산에 못가시나요?', '산에 못가고 장보러 가야지.휴양림가서 산책해야지만보 걸을수 있을런지 모르겠다.', '그러게요 이번주는 걷기 어플 주간미션달성 아직인가요?', '이번주 주간미션 달성했어.획득한 리워드가 기다리고 있어요.', '이번주도 하셨네요걷기운동으로 커피쿠폰 또 받을 수 있겠어요', '그래. 별것아닌것 같아도 보람이 있다.', '네 만보걷기는 어플 채우는 재미도 큰 거 같아요', '건강을 위해서 걷기하는데 만보 채우는 재미도 있어.', '네 걷기운동 안하면 어플이 빈털털이 느낌이라 아쉬운감이 있어요', '어플도 채우고 건강도 챙기고 네가 이런저런 어플 알려줘서 재미도 있고 보람도 있어.', '엄마가 걸어서 모으신 포인트를 유 용하게 사용하셔야 더 재밌을텐데요빵도 사드시고 많이 모으면 치킨도 사드시고 하세요 ㅎㅎ', '그냥 걸어도 건강해져서 좋은데 덤으로 생기는 포인트들이 있으니 더 좋아한달동안 걸어서 토스적립금도 재밌고오늘도 계좌로 입금했어.', '매달 말일에 하면 잊지않고 좋겠네요']\n"
     ]
    }
   ],
   "source": [
    "print(data_train['conversation'][1])\n",
    "print()\n",
    "print(token_split(data_train['conversation'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbf4cf0",
   "metadata": {
    "id": "c0a719f8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273/1909354095.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train['conversation'] = data_train['conversation'].apply(token_split)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[나 운전면허 따야 하는데, 너 따긴 했잖아?연수를 받아야지 너는, 맞아 연수를 길...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[내일은 산에 못가시나요?, 산에 못가고 장보러 가야지.휴양림가서 산책해야지만보 걸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[오늘 도서관가서 책 빌려왔음, 오호 도서관도 가나? 어디도서관?, 거기 상인동에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[파운데이션 하나 같이 테스트 하러 가자, 오 파운데이션 다 썼어?, 옹옹 파데는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[비긴 어게인 다시 보고 싶다, 아 나는 그거 또보고싶다고!, ㅎㅎ 배우들 연기력이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[나 오늘 차 계약했어., 어머. 내가 소개시켜준 딜러한테?, 응응 전화해봤는데 엄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[가족 여행을 어디로 갈까나, 오 아직도 못 정했어?, 웅웅ㅜ 뭔가 우리가 정하기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[나 보톡스 맞아볼려고!, 그거 일회성이 아닌건 알고 있지? ㅋㅋ, 알지 46개월 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[엄마 네일 한 지 좀 오래되지 않았어?, 엄마는 원래 자주 안 해서 괜찮아., 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[오토바이 소리가 왜 다르지?, 나도 그게 궁금했어, 어떤 건 소리가 엄청 크잖아,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         conversation\n",
       "0   [나 운전면허 따야 하는데, 너 따긴 했잖아?연수를 받아야지 너는, 맞아 연수를 길...\n",
       "1   [내일은 산에 못가시나요?, 산에 못가고 장보러 가야지.휴양림가서 산책해야지만보 걸...\n",
       "2   [오늘 도서관가서 책 빌려왔음, 오호 도서관도 가나? 어디도서관?, 거기 상인동에 ...\n",
       "3   [파운데이션 하나 같이 테스트 하러 가자, 오 파운데이션 다 썼어?, 옹옹 파데는 ...\n",
       "4   [비긴 어게인 다시 보고 싶다, 아 나는 그거 또보고싶다고!, ㅎㅎ 배우들 연기력이...\n",
       "..                                                ...\n",
       "85  [나 오늘 차 계약했어., 어머. 내가 소개시켜준 딜러한테?, 응응 전화해봤는데 엄...\n",
       "86  [가족 여행을 어디로 갈까나, 오 아직도 못 정했어?, 웅웅ㅜ 뭔가 우리가 정하기 ...\n",
       "87  [나 보톡스 맞아볼려고!, 그거 일회성이 아닌건 알고 있지? ㅋㅋ, 알지 46개월 ...\n",
       "88  [엄마 네일 한 지 좀 오래되지 않았어?, 엄마는 원래 자주 안 해서 괜찮아., 이...\n",
       "89  [오토바이 소리가 왜 다르지?, 나도 그게 궁금했어, 어떤 건 소리가 엄청 크잖아,...\n",
       "\n",
       "[90 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['conversation'] = data_train['conversation'].apply(token_split)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4fd9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[나 운전면허 따야 하는데, 너 따긴 했잖아?연수를 받아야지 너는, 맞아 연수를 길...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[내일은 산에 못가시나요?, 산에 못가고 장보러 가야지.휴양림가서 산책해야지만보 걸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[오늘 도서관가서 책 빌려왔음, 오호 도서관도 가나? 어디도서관?, 거기 상인동에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[파운데이션 하나 같이 테스트 하러 가자, 오 파운데이션 다 썼어?, 옹옹 파데는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[비긴 어게인 다시 보고 싶다, 아 나는 그거 또보고싶다고!, ㅎㅎ 배우들 연기력이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[나 오늘 차 계약했어., 어머. 내가 소개시켜준 딜러한테?, 응응 전화해봤는데 엄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[가족 여행을 어디로 갈까나, 오 아직도 못 정했어?, 웅웅ㅜ 뭔가 우리가 정하기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[나 보톡스 맞아볼려고!, 그거 일회성이 아닌건 알고 있지? ㅋㅋ, 알지 46개월 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[엄마 네일 한 지 좀 오래되지 않았어?, 엄마는 원래 자주 안 해서 괜찮아., 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[오토바이 소리가 왜 다르지?, 나도 그게 궁금했어, 어떤 건 소리가 엄청 크잖아,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         conversation\n",
       "0   [나 운전면허 따야 하는데, 너 따긴 했잖아?연수를 받아야지 너는, 맞아 연수를 길...\n",
       "1   [내일은 산에 못가시나요?, 산에 못가고 장보러 가야지.휴양림가서 산책해야지만보 걸...\n",
       "2   [오늘 도서관가서 책 빌려왔음, 오호 도서관도 가나? 어디도서관?, 거기 상인동에 ...\n",
       "3   [파운데이션 하나 같이 테스트 하러 가자, 오 파운데이션 다 썼어?, 옹옹 파데는 ...\n",
       "4   [비긴 어게인 다시 보고 싶다, 아 나는 그거 또보고싶다고!, ㅎㅎ 배우들 연기력이...\n",
       "..                                                ...\n",
       "85  [나 오늘 차 계약했어., 어머. 내가 소개시켜준 딜러한테?, 응응 전화해봤는데 엄...\n",
       "86  [가족 여행을 어디로 갈까나, 오 아직도 못 정했어?, 웅웅ㅜ 뭔가 우리가 정하기 ...\n",
       "87  [나 보톡스 맞아볼려고!, 그거 일회성이 아닌건 알고 있지? ㅋㅋ, 알지 46개월 ...\n",
       "88  [엄마 네일 한 지 좀 오래되지 않았어?, 엄마는 원래 자주 안 해서 괜찮아., 이...\n",
       "89  [오토바이 소리가 왜 다르지?, 나도 그게 궁금했어, 어떤 건 소리가 엄청 크잖아,...\n",
       "\n",
       "[90 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data_train.loc[data_train['conversation'].apply(lambda x: len(x) > 3)].reset_index(drop=True)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3282ebd",
   "metadata": {
    "id": "19375e20",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273/592510162.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val['conversation'] = data_val['conversation'].apply(token_split)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[그거 알아? sns 사용 시간 1위 국가가 필리핀이래., 아니. 처음 알았어. 넌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[님은 다음 생에 결혼하실건가요?, 결혼하면 여자들 일만 늘어나는것 같지 않나요?,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[가을이라 그런지 너무 외롭다., 그러고 보니 너만 여자친구가 없구나., 연애하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[마당에 잔디 깎아야되는데 언제할꺼야?, 나 이번주말에 별일 없으니깐 내가 할께!,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[그리고 또 다른 내친구네 오빠가 고깃집을 하거든, 엉엉 맛있겟다 고기, 천안에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[서울 유명 사립대학교의 영어 유치원이 일을 냈네요., 또 무슨 사고를 쳤나요, 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[군대에서 담배 시작하는 애들이 많더라, 동기들과 어울리기 위해서일까?, 끊임없이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[올드뎌 펜트하우스, 아 펜트하우스가 그래 좋나 ㅋㅋ빨리 치우고 정리해서 본방송 보...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[옛날에는 똥개라고 불렀었는데, 요새는 그말 진짜 안쓰잖아, 시고르자브종 이라고 부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[뭔가 택배가 온듯바닥에 던지는 소리가 났다국밥 산거 왔는가?, 국밥 산느지 좀 됏...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation\n",
       "0  [그거 알아? sns 사용 시간 1위 국가가 필리핀이래., 아니. 처음 알았어. 넌...\n",
       "1  [님은 다음 생에 결혼하실건가요?, 결혼하면 여자들 일만 늘어나는것 같지 않나요?,...\n",
       "2  [가을이라 그런지 너무 외롭다., 그러고 보니 너만 여자친구가 없구나., 연애하는 ...\n",
       "3  [마당에 잔디 깎아야되는데 언제할꺼야?, 나 이번주말에 별일 없으니깐 내가 할께!,...\n",
       "4  [그리고 또 다른 내친구네 오빠가 고깃집을 하거든, 엉엉 맛있겟다 고기, 천안에서 ...\n",
       "5  [서울 유명 사립대학교의 영어 유치원이 일을 냈네요., 또 무슨 사고를 쳤나요, 이...\n",
       "6  [군대에서 담배 시작하는 애들이 많더라, 동기들과 어울리기 위해서일까?, 끊임없이 ...\n",
       "7  [올드뎌 펜트하우스, 아 펜트하우스가 그래 좋나 ㅋㅋ빨리 치우고 정리해서 본방송 보...\n",
       "8  [옛날에는 똥개라고 불렀었는데, 요새는 그말 진짜 안쓰잖아, 시고르자브종 이라고 부...\n",
       "9  [뭔가 택배가 온듯바닥에 던지는 소리가 났다국밥 산거 왔는가?, 국밥 산느지 좀 됏..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val['conversation'] = data_val['conversation'].apply(token_split)\n",
    "data_val = data_val.reset_index(drop=True)\n",
    "\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e63275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[그거 알아? sns 사용 시간 1위 국가가 필리핀이래., 아니. 처음 알았어. 넌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[님은 다음 생에 결혼하실건가요?, 결혼하면 여자들 일만 늘어나는것 같지 않나요?,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[가을이라 그런지 너무 외롭다., 그러고 보니 너만 여자친구가 없구나., 연애하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[마당에 잔디 깎아야되는데 언제할꺼야?, 나 이번주말에 별일 없으니깐 내가 할께!,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[그리고 또 다른 내친구네 오빠가 고깃집을 하거든, 엉엉 맛있겟다 고기, 천안에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[서울 유명 사립대학교의 영어 유치원이 일을 냈네요., 또 무슨 사고를 쳤나요, 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[군대에서 담배 시작하는 애들이 많더라, 동기들과 어울리기 위해서일까?, 끊임없이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[올드뎌 펜트하우스, 아 펜트하우스가 그래 좋나 ㅋㅋ빨리 치우고 정리해서 본방송 보...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[옛날에는 똥개라고 불렀었는데, 요새는 그말 진짜 안쓰잖아, 시고르자브종 이라고 부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[뭔가 택배가 온듯바닥에 던지는 소리가 났다국밥 산거 왔는가?, 국밥 산느지 좀 됏...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation\n",
       "0  [그거 알아? sns 사용 시간 1위 국가가 필리핀이래., 아니. 처음 알았어. 넌...\n",
       "1  [님은 다음 생에 결혼하실건가요?, 결혼하면 여자들 일만 늘어나는것 같지 않나요?,...\n",
       "2  [가을이라 그런지 너무 외롭다., 그러고 보니 너만 여자친구가 없구나., 연애하는 ...\n",
       "3  [마당에 잔디 깎아야되는데 언제할꺼야?, 나 이번주말에 별일 없으니깐 내가 할께!,...\n",
       "4  [그리고 또 다른 내친구네 오빠가 고깃집을 하거든, 엉엉 맛있겟다 고기, 천안에서 ...\n",
       "5  [서울 유명 사립대학교의 영어 유치원이 일을 냈네요., 또 무슨 사고를 쳤나요, 이...\n",
       "6  [군대에서 담배 시작하는 애들이 많더라, 동기들과 어울리기 위해서일까?, 끊임없이 ...\n",
       "7  [올드뎌 펜트하우스, 아 펜트하우스가 그래 좋나 ㅋㅋ빨리 치우고 정리해서 본방송 보...\n",
       "8  [옛날에는 똥개라고 불렀었는데, 요새는 그말 진짜 안쓰잖아, 시고르자브종 이라고 부...\n",
       "9  [뭔가 택배가 온듯바닥에 던지는 소리가 났다국밥 산거 왔는가?, 국밥 산느지 좀 됏..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val = data_val.loc[data_val['conversation'].apply(lambda x: len(x) > 3)].reset_index(drop=True)\n",
    "\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f90dab",
   "metadata": {
    "id": "97e70cae",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = PreTrainedTokenizerFast.from_pretrained(Config.model_name,\n",
    "#             bos_token=Config.bos_token, eos_token=Config.eos_token, unk_token='<unk>',\n",
    "#             pad_token=Config.pad_token, mask_token=Config.mask_token)\n",
    "\n",
    "import sentencepiece as spm\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.load(\"SentencePiece_04.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3bb389b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49186,\n",
       " 4,\n",
       " 1888,\n",
       " 13917,\n",
       " 17938,\n",
       " 16875,\n",
       " 49199,\n",
       " 5,\n",
       " 13917,\n",
       " 73,\n",
       " 1447,\n",
       " 16752,\n",
       " 1668,\n",
       " 49189,\n",
       " 49534,\n",
       " 49462,\n",
       " 49524,\n",
       " 712,\n",
       " 1763,\n",
       " 1248,\n",
       " 38370,\n",
       " 8965,\n",
       " 49247,\n",
       " 558,\n",
       " 27064,\n",
       " 2773,\n",
       " 49189,\n",
       " 4,\n",
       " 39210,\n",
       " 354,\n",
       " 650,\n",
       " 10594,\n",
       " 1822,\n",
       " 9872,\n",
       " 49291,\n",
       " 49782,\n",
       " 49371,\n",
       " 49394,\n",
       " 213,\n",
       " 4524,\n",
       " 49199,\n",
       " 5,\n",
       " 354,\n",
       " 49239,\n",
       " 9872,\n",
       " 49291,\n",
       " 49782,\n",
       " 22930,\n",
       " 437,\n",
       " 49189,\n",
       " 49978,\n",
       " 49805,\n",
       " 49222,\n",
       " 640,\n",
       " 49344,\n",
       " 3715,\n",
       " 3992,\n",
       " 2051,\n",
       " 49189,\n",
       " 4,\n",
       " 354,\n",
       " 1270,\n",
       " 4595,\n",
       " 798,\n",
       " 50047,\n",
       " 49208,\n",
       " 3542,\n",
       " 83,\n",
       " 744,\n",
       " 24009,\n",
       " 158,\n",
       " 1560,\n",
       " 42,\n",
       " 20,\n",
       " 3139,\n",
       " 5,\n",
       " 47,\n",
       " 49189,\n",
       " 324,\n",
       " 49309,\n",
       " 49190,\n",
       " 49557,\n",
       " 49309,\n",
       " 9290,\n",
       " 19489,\n",
       " 729,\n",
       " 49189,\n",
       " 4,\n",
       " 117,\n",
       " 72,\n",
       " 49223,\n",
       " 50047,\n",
       " 674,\n",
       " 1822,\n",
       " 24287,\n",
       " 25515,\n",
       " 522,\n",
       " 11,\n",
       " 2772,\n",
       " 5,\n",
       " 14589,\n",
       " 5339,\n",
       " 10594,\n",
       " 701,\n",
       " 72,\n",
       " 49223,\n",
       " 24287,\n",
       " 25515,\n",
       " 179,\n",
       " 49189,\n",
       " 4,\n",
       " 117,\n",
       " 10594,\n",
       " 3542,\n",
       " 8675,\n",
       " 18850,\n",
       " 2387,\n",
       " 49907,\n",
       " 29907,\n",
       " 13150,\n",
       " 13317,\n",
       " 3230,\n",
       " 2051,\n",
       " 5,\n",
       " 29635,\n",
       " 13866,\n",
       " 1200,\n",
       " 49203,\n",
       " 8949,\n",
       " 3859,\n",
       " 16596,\n",
       " 1822,\n",
       " 12251,\n",
       " 25515,\n",
       " 826,\n",
       " 10721,\n",
       " 49203,\n",
       " 179,\n",
       " 49189,\n",
       " 4,\n",
       " 589,\n",
       " 4618,\n",
       " 3608,\n",
       " 49302,\n",
       " 38277,\n",
       " 170,\n",
       " 461,\n",
       " 240,\n",
       " 2189,\n",
       " 37720,\n",
       " 79,\n",
       " 6788,\n",
       " 3812,\n",
       " 49234,\n",
       " 19141,\n",
       " 10273,\n",
       " 2403,\n",
       " 168,\n",
       " 14488,\n",
       " 15685,\n",
       " 10273,\n",
       " 2403,\n",
       " 6989,\n",
       " 247,\n",
       " 49393,\n",
       " 5,\n",
       " 99,\n",
       " 20259,\n",
       " 1200,\n",
       " 6554,\n",
       " 1195,\n",
       " 9637,\n",
       " 83,\n",
       " 6785,\n",
       " 2486,\n",
       " 337,\n",
       " 3479,\n",
       " 79,\n",
       " 8824,\n",
       " 49371,\n",
       " 2724,\n",
       " 4618,\n",
       " 4913,\n",
       " 49404,\n",
       " 49803,\n",
       " 18478,\n",
       " 15834,\n",
       " 9047,\n",
       " 10685,\n",
       " 2624,\n",
       " 437,\n",
       " 49189,\n",
       " 4,\n",
       " 6612,\n",
       " 46,\n",
       " 961,\n",
       " 293,\n",
       " 8577,\n",
       " 49381,\n",
       " 49194,\n",
       " 29202]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"\"\"\n",
    "<usr> 내일은 산에 못가시나요?<sys> 산에 못가고 장보러 가야지.휴양림가서 산책해야지만보 걸을수 있을런지 모르겠다.<usr> 그러게요 이번주는 걷기 어플 주간미션달성 아직인가요?<sys> 이번주 주간미션 달성했어.획득한 리워드가 기다리고 있어요.<usr> 이번주도 하셨네요걷기운동으로 커피쿠폰 또 받을 수 있겠어요<sys> 그래. 별것아닌것 같아도 보람이 있다.<usr> 네 만보걷기는 어플 채우는 재미도 큰 거 같아요<sys> 건강을 위해서 걷기하는데 만보 채우는 재미도 있어.<usr> 네 걷기운동 안하면 어플이 빈털털이 느낌이라 아쉬운감이 있어요<sys> 어플도 채우고 건강도 챙기고 네가 이런저런 어플 알려줘서 재미도 있고 보람도 있어.<usr> 엄마가 걸어서 모으신 포인트를 유 용하게 사용하셔야 더 재밌을텐데요빵도 사드시고 많이 모으면 치킨도 사드시고 하세요 ㅎㅎ<sys> 그냥 걸어도 건강해져서 좋은데 덤으로 생기는 포인트들이 있으니 더 좋아한달동안 걸어서 토스적립금도 재밌고오늘도 계좌로 입금했어.<usr> 매달 말일에 하면 잊지않고 좋겠네요\n",
    "\"\"\"\n",
    "tokenizer.encode(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d86dbb5c",
   "metadata": {
    "id": "8dc0b0db"
   },
   "outputs": [],
   "source": [
    "# 데이터셋\n",
    "# 전처리 후, 텀을 나눠놓은 상태의 데이터를 입력으로 받음\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "        입력 : 전처리 후 대화 분리까지 완료된 데이터\n",
    "            ex) [\"밥 먹었어?\", \"응 밥 먹었어\", \"뭐 먹었어?\", \"샌드위치 먹었어\"]\n",
    "        출력 : 패딩까지 완료된 input_ids, token_type_ids, labels\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer, Config):\n",
    "        self.data = data\n",
    "        self.usr_token = Config.usr_token\n",
    "        self.sys_token = Config.sys_token\n",
    "        self.bos_token = Config.bos_token\n",
    "        self.eos_token = Config.eos_token\n",
    "        self.mask_token = Config.mask_token\n",
    "        self.pad_token = Config.pad_token\n",
    "        self.max_len = Config.max_len\n",
    "        self.max_turns = Config.max_turns\n",
    "        \n",
    "        self.input_ids = []\n",
    "        self.token_type_ids = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in tqdm(range(len(self.data))):\n",
    "            hists = []\n",
    "            dials = self.data[i]\n",
    "            \n",
    "            for u, utter in enumerate(dials):\n",
    "                if u % 2 == 0:\n",
    "                    hists.append(self.usr_token + utter)  # Speaker 1: User\n",
    "                else:\n",
    "                    hists.append(self.sys_token + utter)  # Speaker 2: System\n",
    "            \n",
    "            max_turn = max(len(hists), self.max_turns) # max_turns을 넘으면 post\n",
    "            if max_turn % 2 != 0: max_turn -= 1 # user 대화로 끝남 방지\n",
    "                \n",
    "            for f in range(max_turn, 1, -2):\n",
    "                contexts = hists[:f]\n",
    "                if sum([len(l) for l in contexts]) > self.max_len-2: continue # bos_token와 eos_token 토큰을 추가하기 위해 -2\n",
    "                contexts[0] = self.bos_token + contexts[0]\n",
    "                contexts[-1] = contexts[-1] + self.eos_token\n",
    "                contexts = [tokenizer.encode(ctx) for ctx in contexts]\n",
    "                \n",
    "                token_type_id = [[ctx[0]] * len(ctx) if c != 0 else [ctx[1]] * len(ctx) for c, ctx in enumerate(contexts)]\n",
    "                label = [[-100] * len(ctx) if c != len(contexts)-1 else [-100] + ctx[1:] for c, ctx in enumerate(contexts)]\n",
    "                \n",
    "                input_id = list(chain.from_iterable(contexts))\n",
    "                token_type_id = list(chain.from_iterable(token_type_id))\n",
    "                label = list(chain.from_iterable(label))\n",
    "                \n",
    "                assert len(input_id) == len(token_type_id) == len(label), \"There is something wrong in dialogue process.\"\n",
    "                \n",
    "                input_id, token_type_id, label = self.make_padding(input_id, token_type_id, label)\n",
    "                \n",
    "                self.input_ids.append(input_id)\n",
    "                self.token_type_ids.append(token_type_id)\n",
    "                self.labels.append(label)\n",
    "                \n",
    "                break\n",
    "    \n",
    "    def make_padding(self, input_id, token_type_id, label):\n",
    "        left = self.max_len - len(input_id)\n",
    "        \n",
    "#         input_id += [tokenizer.pad_token_id] * left\n",
    "#         token_type_id += [tokenizer.pad_token_id] * left\n",
    "        input_id += [tokenizer.pad_id()] * left\n",
    "        token_type_id += [tokenizer.pad_id()] * left\n",
    "        label += [-100] * left\n",
    "        \n",
    "        return input_id, token_type_id, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.token_type_ids[idx], self.labels[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d89b0a9",
   "metadata": {
    "id": "541142b6"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    mask = [item[1] for item in batch]\n",
    "    label = [item[2] for item in batch]\n",
    "    \n",
    "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d0ad9f6",
   "metadata": {
    "id": "541142b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 3780.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n",
    "train_set = CustomDataset(data_train['conversation'], tokenizer, Config)\n",
    "train_dataloader = DataLoader(train_set, batch_size=6, num_workers=2, shuffle=True, collate_fn=collate_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1657ceeb",
   "metadata": {
    "id": "0951b854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids ====>  tensor([[49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0]])\n",
      "mask =====>  tensor([[2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0]])\n",
      "label =====>  tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])\n",
      "(tensor([[49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0],\n",
      "        [49186,     2,     4,  ...,     0,     0,     0]]), tensor([[2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0],\n",
      "        [2, 2, 2,  ..., 0, 0, 0]]), tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]]))\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, samples in enumerate(train_dataloader):\n",
    "    if batch_idx > 0:\n",
    "        break\n",
    "    token_ids, mask, label = samples\n",
    "    print(\"token_ids ====> \", token_ids)\n",
    "    print(\"mask =====> \", mask)\n",
    "    print(\"label =====> \", label)\n",
    "    print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c4a34f1",
   "metadata": {
    "id": "7e77f4a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 2259.62it/s]\n"
     ]
    }
   ],
   "source": [
    "val_set = CustomDataset(data_val['conversation'], tokenizer, Config)\n",
    "val_dataloader = DataLoader(val_set, batch_size=6, num_workers=2, shuffle=True, collate_fn=collate_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f98bf4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_id(), tokenizer.eos_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf18158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(Config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe5f91e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_num_labels\": 1,\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
       "  \"bos_token_id\": 0,\n",
       "  \"created_date\": \"2021-04-28\",\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0\n",
       "  },\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"pad_token_id\": 3,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.11.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 51200\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = AutoConfig.from_pretrained(Config.model_name)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41433f91",
   "metadata": {
    "id": "a5429c3a"
   },
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    \"\"\"\n",
    "        __init__ : 챗봇 모델 생성\n",
    "            Args : model, tokenizer, Config\n",
    "        \n",
    "        train : 모델 학습 진행\n",
    "            Args : epochs, train_data, (validation_data), (save)\n",
    "        \n",
    "        load_model : 모델 불러오기\n",
    "            Args : PATH\n",
    "        \n",
    "        save_model : 모델 저장하기\n",
    "            Args : PATH\n",
    "        \n",
    "        talk : 챗봇 대화하기\n",
    "            대화 종료 멘트 : quit\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, Config):\n",
    "        \"\"\"\n",
    "            Args : model, tokenizer, Config\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = Config.device\n",
    "        self.name = Config.model_name\n",
    "        self.optim = torch.optim.Adam(model.parameters(), lr=Config.learning_rate)\n",
    "        \n",
    "#         self.user_token_id = tokenizer.get_vocab()[Config.usr_token]\n",
    "#         self.bot_token_id = tokenizer.get_vocab()[Config.sys_token]\n",
    "        self.user_token_id = tokenizer.PieceToId(Config.usr_token)\n",
    "        self.bot_token_id = tokenizer.PieceToId(Config.sys_token)\n",
    "        self.max_len = Config.max_len\n",
    "        self.max_turns = Config.max_turns\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train(self, epochs, train_data, validation_data=None, save=None):\n",
    "        \"\"\"\n",
    "            epochs, train_data, validation_data=None, save=None\n",
    "            save : epoch마다 모델을 저장할 경로/파일명\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            print(f\"\\n Epoch {epoch+1}/{epochs}\", sep=\"\\n\")\n",
    "            starttime = time.time()\n",
    "            batch_loss = []\n",
    "\n",
    "            for i, batch in enumerate(train_data):\n",
    "                input_ids, token_type_ids, labels = batch\n",
    "                input_ids, token_type_ids, labels = \\\n",
    "                    input_ids.to(self.device), token_type_ids.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss, logits = outputs[0], outputs[1]\n",
    "                \n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                batch_loss.append(loss.item())\n",
    "                \n",
    "                print(self.status(i+1, len(train_data), time.time()-starttime, np.mean(batch_loss)), end='\\r')\n",
    "\n",
    "            self.losses.append(np.mean(batch_loss))\n",
    "            \n",
    "            if validation_data:\n",
    "                val_loss = self.validation(validation_data)\n",
    "                print(self.status(i+1, len(train_data), time.time()-starttime, np.mean(batch_loss)) + \\\n",
    "                      \" | val_loss : %.6f\"%(val_loss), end='\\r')\n",
    "                self.val_losses.append(val_loss)\n",
    "            \n",
    "            if save:\n",
    "                PATH = f'{save}_epochs-{epoch+1}_loss-{np.mean(batch_loss)}.pth'\n",
    "                torch.save(self.model.state_dict(), PATH)\n",
    "                \n",
    "    def validation(self, validation_data):\n",
    "        self.model.eval()\n",
    "        batch_loss = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(validation_data):\n",
    "                input_ids, token_type_ids, labels = batch\n",
    "                input_ids, token_type_ids, labels = \\\n",
    "                    input_ids.to(self.device), token_type_ids.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss, logits = outputs[0], outputs[1]\n",
    "                batch_loss.append(loss.item())\n",
    "            \n",
    "            valid_loss = np.mean(batch_loss)\n",
    "        \n",
    "        return valid_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def status(step, step_len, time, loss):\n",
    "        return \"step : %d/%d - %ds | loss : %.6f | %.2fit/s\"%(\n",
    "            step,\n",
    "            step_len,\n",
    "            int(time),\n",
    "            loss,\n",
    "            step/time\n",
    "        )\n",
    "    \n",
    "    def load_model(self, PATH):\n",
    "        \"\"\"\n",
    "            PATH : pth 파일이 저장된 경로\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(torch.load(PATH))\n",
    "        print(\"model loaded.\")\n",
    "    \n",
    "    def save_model(self, PATH=None):\n",
    "        \"\"\"\n",
    "            PATH : 저장할 파일 경로/이름, 생략시 모델 이름과 현재 시간을 파일명으로 지정함\n",
    "        \"\"\"\n",
    "        if not PATH:\n",
    "            name = self.name.replace(\"/\", \"-\")\n",
    "            PATH = f\"./{name}_{time.strftime('%Y-%m-%d %H:%M:%S')}.pth\"\n",
    "        torch.save(self.model.state_dict(), PATH)\n",
    "        print(\"model saved.\")\n",
    "    \n",
    "    def talk(self):\n",
    "        print(\"Escape ment : quit\")\n",
    "        with torch.no_grad():\n",
    "            cur_speaker = 1\n",
    "            input_ids_list = []\n",
    "            token_type_ids_list = []\n",
    "            t = 0\n",
    "            output_id = None\n",
    "\n",
    "            while True:\n",
    "                if cur_speaker == 1:\n",
    "                    cur_speaker_id = self.user_token_id\n",
    "                    utter = input(\"You: \")\n",
    "\n",
    "                    if utter == \"quit\":\n",
    "                        print(\"Bot: Good bye.\")\n",
    "                        break\n",
    "\n",
    "                    input_id = [cur_speaker_id] + self.tokenizer.encode(utter)\n",
    "\n",
    "                    if t == 0:\n",
    "#                         input_id = [self.tokenizer.bos_token_id] + input_id\n",
    "                        input_id = [self.tokenizer.bos_id()] + input_id\n",
    "                else:\n",
    "                    cur_speaker_id = self.bot_token_id\n",
    "                    input_id = copy.deepcopy(output_id)\n",
    "\n",
    "                token_type_id = [cur_speaker_id] * len(input_id)\n",
    "\n",
    "#                 if input_id[-1] == self.tokenizer.eos_token_id:\n",
    "                if input_id[-1] == self.tokenizer.eos_id():\n",
    "                    input_id = input_id[:-1]\n",
    "                    token_type_id = token_type_id[:-1] \n",
    "\n",
    "                input_ids_list.append(input_id)\n",
    "                token_type_ids_list.append(token_type_id)\n",
    "\n",
    "                if t >= self.max_turns:\n",
    "                    input_ids_list = input_ids_list[1:]\n",
    "                    token_type_ids_list = token_type_ids_list[1:]\n",
    "\n",
    "                next_speaker = (cur_speaker % 2) + 1\n",
    "                if next_speaker == 1:\n",
    "                    next_speaker_id = self.user_token_id\n",
    "                else:\n",
    "                    next_speaker_id = self.bot_token_id\n",
    "\n",
    "                if cur_speaker == 1:\n",
    "                    output_id = self.nucleus_sampling(input_ids_list, token_type_ids_list, next_speaker_id)\n",
    "                    res = self.tokenizer.decode(output_id)\n",
    "\n",
    "                    print(f\"Bot: {res}\")\n",
    "\n",
    "                cur_speaker = copy.deepcopy(next_speaker)\n",
    "                t += 1\n",
    "\n",
    "    def nucleus_sampling(self, input_ids_list, token_type_ids_list, next_speaker_id):\n",
    "        output_id = []\n",
    "        res_id = [next_speaker_id]\n",
    "        res_type_id = [next_speaker_id]\n",
    "        \n",
    "        for pos in range(self.max_len):\n",
    "            input_ids = list(chain.from_iterable(input_ids_list)) + res_id\n",
    "            token_type_ids = list(chain.from_iterable(token_type_ids_list)) + res_type_id\n",
    "            input_len = len(input_ids)\n",
    "\n",
    "            left = self.max_len - len(input_ids)\n",
    "#             input_ids += [self.tokenizer.pad_token_id] * left\n",
    "#             token_type_ids += [self.tokenizer.pad_token_id] * left\n",
    "            input_ids += [self.tokenizer.pad_id()] * left\n",
    "            token_type_ids += [self.tokenizer.pad_id()] * left\n",
    "\n",
    "            assert len(input_ids) == len(token_type_ids), \"There is something wrong in dialogue process.\"\n",
    "\n",
    "            input_ids = torch.LongTensor(input_ids).unsqueeze(0).to(self.device)  # (1, L)\n",
    "            token_type_ids = torch.LongTensor(token_type_ids).unsqueeze(0).to(self.device)  # (1, L)\n",
    "            output = self.model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "            output = self.model(input_ids=input_ids, token_type_ids=token_type_ids)[0][:, input_len-1]  # (1, vocab_size)\n",
    "            output = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "\n",
    "            sorted_probs, sorted_idxs = torch.sort(output, descending=True)\n",
    "            cumsum_probs = torch.cumsum(sorted_probs, dim=-1)  # (1, vocab_size)\n",
    "            idx_remove = cumsum_probs > 0.9\n",
    "            sorted_probs[idx_remove] = 1e-8\n",
    "            sorted_probs /= torch.sum(sorted_probs, dim=-1, keepdim=True)  # (1, vocab_size)\n",
    "\n",
    "            # Random sampling\n",
    "            probs = torch.zeros(output.shape).to(self.device).scatter_(-1, sorted_idxs, sorted_probs)  # (1, vocab_size)\n",
    "            idx = torch.multinomial(probs, 1).squeeze(-1).squeeze(0).item()\n",
    "\n",
    "#             if len(output_id) == self.max_len or idx == self.tokenizer.eos_token_id:\n",
    "            if len(output_id) == self.max_len or idx == self.tokenizer.eos_id():\n",
    "                break\n",
    "            else:\n",
    "                output_id.append(idx)\n",
    "                res_id.append(idx)\n",
    "                res_type_id.append(next_speaker_id)\n",
    "\n",
    "        return output_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe7b63d0",
   "metadata": {
    "id": "9c95f9a4"
   },
   "outputs": [],
   "source": [
    "prototype = ChatBot(model, tokenizer, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b050f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9dad0c6",
   "metadata": {
    "id": "a311f244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/1\n",
      "model loaded.- 13s | loss : 11.748104 | 1.11it/s | val_loss : 9.981423\n"
     ]
    }
   ],
   "source": [
    "prototype.train(Config.epochs, train_dataloader, val_dataloader)\n",
    "prototype.load_model(\"skt-kogpt2-base-v2_2023-02-02 19:30:05.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53ff75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained('models/temp.pt')\n",
    "# prototype.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a0bd728",
   "metadata": {
    "id": "40a71ad7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prototype.losses)\n",
    "plt.plot(prototype.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cce44e3",
   "metadata": {
    "id": "560c8fe1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape ment : quit\n",
      "You: 안녕 ㅋㅋ\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_273/2815207564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprototype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_273/2051589094.py\u001b[0m in \u001b[0;36mtalk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcur_speaker\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                     \u001b[0moutput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnucleus_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_speaker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_273/2051589094.py\u001b[0m in \u001b[0;36mnucleus_sampling\u001b[0;34m(self, input_ids_list, token_type_ids_list, next_speaker_id)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1, L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1, L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (1, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m    955\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 )\n\u001b[1;32m    797\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/activations.py\u001b[0m in \u001b[0;36mgelu_new\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mthe\u001b[0m \u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "prototype.talk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3124daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.unk_id()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
